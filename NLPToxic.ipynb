{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\salmansaeed.khan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\salmansaeed.khan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import sys as sys\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 id                                       comment_text  toxic  \\\n",
      "0  0000997932d777bf  Explanation\\r\\nWhy the edits made under my use...      0   \n",
      "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
      "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
      "3  0001b41b1c6bb37e  \"\\r\\nMore\\r\\nI can't make any real suggestions...      0   \n",
      "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
      "\n",
      "   severe_toxic  obscene  threat  insult  identity_hate  \n",
      "0             0        0       0       0              0  \n",
      "1             0        0       0       0              0  \n",
      "2             0        0       0       0              0  \n",
      "3             0        0       0       0              0  \n",
      "4             0        0       0       0              0  \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-358a874b97b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'D:/Personal-GIT/data/kaggle_toxic/train.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdf_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_test' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('D:/Personal-GIT/data/kaggle_toxic/train.csv')\n",
    "print(df.head())\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize Words - Check Distribution of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['token_list'] = df['comment_text'].apply(lambda x: nltk.word_tokenize(x))\n",
    "all_tokens = [item for sublist in df['token_list'] for item in sublist]\n",
    "vocab_all = nltk.FreqDist(all_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_words = {k: v for k, v in vocab_all.items() if k.isalpha()}\n",
    "vocab_words = {k: v for k, v in sorted(vocab_words.items(), key=lambda item: item[1], reverse=True)}\n",
    "vocab_series = pd.Series(dict(vocab_words))\n",
    "#vocab_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "vocab_series_top = vocab_series[:25]\n",
    "all_plot = sns.barplot(x=vocab_series_top.index, y=100*vocab_series_top.values/sum(vocab_series.values), ax=ax)\n",
    "plt.xticks(rotation=30);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Common Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "s=set(stopwords.words('english'))\n",
    "vocab_words\n",
    "vocab_words = {k: v for k, v in vocab_words.items() if k not in s}\n",
    "vocab_words = {k: v for k, v in sorted(vocab_words.items(), key=lambda item: item[1], reverse=True)}\n",
    "vocab_series = pd.Series(dict(vocab_words))\n",
    "vocab_series\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "vocab_series_top = vocab_series[:25]\n",
    "all_plot = sns.barplot(x=vocab_series_top.index, y=100*vocab_series_top.values/sum(vocab_series.values), ax=ax)\n",
    "plt.xticks(rotation=30);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Data in train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getrecursionlimit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Train Test Data\n",
    "df_train = pd.read_csv('D:/Personal-GIT/data/kaggle_toxic/train.csv')\n",
    "df_test = pd.read_csv('D:/Personal-GIT/data/kaggle_toxic/test.csv')\n",
    "y_test  = pd.read_csv('D:/Personal-GIT/data/kaggle_toxic/test_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize Words\n",
    "df_train['token_list'] = df_train['comment_text'].apply(lambda x: nltk.word_tokenize(x))\n",
    "df_test['token_list'] = df_test['comment_text'].apply(lambda x: nltk.word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab length 151\n"
     ]
    }
   ],
   "source": [
    "#Define vocab for the models and exclude stopping words.\n",
    "min_word_length=3\n",
    "max_word_length=10\n",
    "frequency_word =2.5/100*round(df_train.shape[0])\n",
    "s=set(stopwords.words('english'))\n",
    "\n",
    "#Stemming\n",
    "ps = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "df_train['token_list_processed'] = df_train['token_list'].apply(lambda x: set([lemmatizer.lemmatize(v) for v in x if ((len(v)>=min_word_length) & (len(v)<=max_word_length) & (v.isalpha()) & (v not in s))]))\n",
    "df_test['token_list_processed'] = df_test['token_list'].apply(lambda x: set([lemmatizer.lemmatize(v) for v in x if ((len(v)>=min_word_length) & (len(v)<=max_word_length) & (v.isalpha()) & (v not in s))]))\n",
    "\n",
    "#Add count of tokens\n",
    "df_train['token_count'] = df_train['token_list'].apply(lambda x: len(x))\n",
    "df_test['token_count'] = df_test['token_list'].apply(lambda x: len(x))\n",
    "\n",
    "#Relevant Vocabulary from train set\n",
    "all_tokens = [item for sublist in df_train['token_list_processed'] for item in sublist]\n",
    "vocab_all = nltk.FreqDist(all_tokens)\n",
    "vocab_words = {k: v for k, v in vocab_all.items() if v>=frequency_word} #keep words with alteast occurance of more than 2%\n",
    "#vocab_words = {k: v for k, v in vocab_words.items() if v<=0.90*round(df.shape[0])} #keep words with alteast occurance of more than 0.5%\n",
    "print(f'Vocab length {len(vocab_words)}')\n",
    "df_train['token_list_processed_reduced_vocab'] = df_train['token_list_processed'].apply(lambda x: set([v for v in x if v in vocab_words]))\n",
    "df_test['token_list_processed_reduced_vocab'] = df_test['token_list_processed'].apply(lambda x: set([v for v in x if v in vocab_words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One Hot encoding for relevant vocabulary on test and train sets.\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(analyzer=lambda x: x)\n",
    "vectorizer.fit(df_train['token_list_processed_reduced_vocab'])\n",
    "features = vectorizer.get_feature_names()\n",
    "len(features)\n",
    "\n",
    "X_train = vectorizer.transform(df_train['token_list_processed_reduced_vocab'])\n",
    "count_vect_df_train = pd.DataFrame(X_train.toarray(), columns=vectorizer.get_feature_names())\n",
    "df_train = pd.concat([df_train, count_vect_df_train], axis=1)\n",
    "\n",
    "#Test-data Encoding\n",
    "X_test = vectorizer.transform(df_test['token_list_processed_reduced_vocab'])\n",
    "count_vect_df_test = pd.DataFrame(X_test.toarray(), columns=vectorizer.get_feature_names())\n",
    "df_test = pd.concat([df_test, count_vect_df_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training & Test Data - subset relevant features\n",
    "X_train = df_train.drop(columns=['id', 'comment_text','toxic','severe_toxic', 'obscene','threat','insult',\n",
    "                                 'identity_hate','token_list','token_list_processed','token_list_processed_reduced_vocab'])\n",
    "y_train = df_train[['toxic','severe_toxic', 'obscene','threat','insult','identity_hate']].apply(lambda x: 1 if sum(x) else 0, axis=1)\n",
    "X_test = df_test.drop(columns=['id','comment_text','token_list','token_list_processed','token_list_processed_reduced_vocab'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Features Shape = (159571, 152)\n",
      "Test Features Shape = (153164, 152)\n",
      "Relevant Test Features Shape = (63978, 152)\n",
      "Train set y mean = 0.10167887648758234\n",
      "Test set y mean = 0.09758041826877989\n"
     ]
    }
   ],
   "source": [
    "#Relevant Test Data - remove test sets where predictions missing.\n",
    "y_test[['target']] = y_test[['toxic','severe_toxic', 'obscene','threat','insult','identity_hate']].apply(lambda x: 1 if sum(x) else 0, axis=1)\n",
    "y_test[['Missing']] = y_test[['toxic','severe_toxic', 'obscene','threat','insult','identity_hate']].apply(lambda x: min(x), axis=1)\n",
    "y_test_relevant = y_test[y_test['Missing']!=-1]['target']\n",
    "X_test_relevant = X_test[y_test['Missing']!=-1]\n",
    "\n",
    "#Dimenstions of test and train sets.\n",
    "print(f'Train Features Shape = {X_train.shape}')\n",
    "print(f'Test Features Shape = {X_test.shape}')\n",
    "print(f'Relevant Test Features Shape = {X_test_relevant.shape}')\n",
    "\n",
    "#Compare - Train Test Distributions.\n",
    "print(f'Train set y mean = {np.mean(y_train)}')\n",
    "print(f'Test set y mean = {np.mean(y_test_relevant)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the best ML Model for Classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tpot\\builtins\\__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.\n",
      "  warnings.warn(\"Warning: optional dependency `torch` is not available. - skipping import of NN models.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Optimization Progress'), FloatProgress(value=0.0, max=200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.8997750226253816\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.8998940894842418\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.8998940894842418\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.8998940894842418\n",
      "\n",
      "Best pipeline: LogisticRegression(GaussianNB(input_matrix), C=15.0, dual=False, penalty=l2)\n"
     ]
    }
   ],
   "source": [
    "## TRAIN MODEL\n",
    "#TPOT Classifier\n",
    "#!pip install tpot\n",
    "from tpot import TPOTClassifier\n",
    "tpot = TPOTClassifier(generations=4, population_size=40, verbosity=2, random_state=42)\n",
    "tpot.fit(X_train, y_train)\n",
    "tpot.export('tpot_products_pipeline.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tpot\\builtins\\__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.\n",
      "  warnings.warn(\"Warning: optional dependency `torch` is not available. - skipping import of NN models.\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from tpot.builtins import StackingEstimator\n",
    "from tpot.export_utils import set_param_recursive\n",
    "\n",
    "# Average CV score on the training set was: 0.8998940894842418\n",
    "exported_pipeline = make_pipeline(\n",
    "    StackingEstimator(estimator=GaussianNB()),\n",
    "    LogisticRegression(C=15.0, dual=False, penalty=\"l2\",solver='lbfgs', max_iter=1000)\n",
    ")\n",
    "# Fix random state for all the steps in exported pipeline\n",
    "set_param_recursive(exported_pipeline.steps, 'random_state', 42)\n",
    "\n",
    "exported_pipeline.fit(X_train, y_train)\n",
    "prediction = exported_pipeline.predict(X_test_relevant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.9, Precision = 0.33068362480127184, Recall = 0.033317315393240426, F1-score = 0.06053550640279395\n",
      "Confusion Matrix is:\n",
      "[[57314   421]\n",
      " [ 6035   208]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score as accuracy\n",
    "from sklearn.metrics import recall_score as recall\n",
    "from sklearn.metrics import precision_score as precision\n",
    "from sklearn.metrics import f1_score\n",
    " \n",
    "cmtp = confusion_matrix(y_test_relevant, prediction)\n",
    "acc  = accuracy(y_test_relevant, prediction)\n",
    "rec  = recall(y_test_relevant, prediction)\n",
    "prec = precision(y_test_relevant, prediction)\n",
    "f1   = f1_score(y_test_relevant, prediction)\n",
    "print(f'Accuracy = {round(acc,2)}, Precision = {prec}, Recall = {rec}, F1-score = {f1}')\n",
    "print('Confusion Matrix is:')\n",
    "print(cmtp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn - Count Vectorizer\n",
    "CountVectorizer implements both tokenization and occurrence counting in a single class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Train Test Data\n",
    "df_train = pd.read_csv('D:/Personal-GIT/data/kaggle_toxic/train.csv')\n",
    "df_test = pd.read_csv('D:/Personal-GIT/data/kaggle_toxic/test.csv')\n",
    "y_test  = pd.read_csv('D:/Personal-GIT/data/kaggle_toxic/test_labels.csv')\n",
    "\n",
    "## Test train features\n",
    "X_train = df_train.drop(columns=['id', 'toxic','severe_toxic', 'obscene','threat','insult','identity_hate'])\n",
    "X_test  = df_test.drop(columns=['id']) \n",
    "y_train = df_train[['toxic','severe_toxic', 'obscene','threat','insult','identity_hate']].apply(lambda x: 1 if sum(x) else 0, axis=1)\n",
    "y_test[['target']] = y_test[['toxic','severe_toxic', 'obscene','threat','insult','identity_hate']].apply(lambda x: 1 if sum(x) else 0, axis=1)\n",
    "y_test[['Missing']] = y_test[['toxic','severe_toxic', 'obscene','threat','insult','identity_hate']].apply(lambda x: min(x), axis=1)\n",
    "y_test_relevant = y_test[y_test['Missing']!=-1]['target']\n",
    "X_test_relevant = X_test[y_test['Missing']!=-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenght of vocabulary = 189460\n",
      "Train Features Shape = (159571, 189460)\n",
      "Relevant Test Features Shape = (63978, 189460)\n",
      "Train set y mean = 0.10167887648758234\n",
      "Test set y mean = 0.09758041826877989\n"
     ]
    }
   ],
   "source": [
    "#Sklearn - CountVectorizer\n",
    "import operator\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer(stop_words='english').fit(X_train['comment_text'])\n",
    "\n",
    "#Longest 10 words\n",
    "[(token, len(token)) for token in vect.vocabulary_.keys()]\n",
    "sorted([(token, len(token)) for token in vect.vocabulary_.keys()], key=operator.itemgetter(1), reverse=True)[0] \n",
    "\n",
    "#Length of vocabulary\n",
    "print(f'Length of vocabulary = {len(vect.vocabulary_.keys())}')\n",
    "\n",
    "# Transform test and train data\n",
    "X_train_transformed = vect.fit_transform(X_train['comment_text'])\n",
    "X_test_transformed = vect.transform(X_test_relevant['comment_text'])\n",
    "\n",
    "#Dimenstions of test and train sets.\n",
    "print(f'Train Features Shape = {X_train_transformed.shape}')\n",
    "print(f'Relevant Test Features Shape = {X_test_transformed.shape}')\n",
    "\n",
    "#Compare - Train Test Distributions.\n",
    "print(f'Train set y mean = {np.mean(y_train)}')\n",
    "print(f'Test set y mean = {np.mean(y_test_relevant)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Optimization Progress'), FloatProgress(value=0.0, max=200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.9552550249828846\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.955605966964464\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.9558754386237233\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.9571977297478277\n",
      "\n",
      "Best pipeline: LinearSVC(input_matrix, C=0.5, dual=False, loss=squared_hinge, penalty=l1, tol=0.1)\n"
     ]
    }
   ],
   "source": [
    "## TRAIN MODEL\n",
    "#TPOT Sparse Classsifier \n",
    "from tpot import TPOTClassifier\n",
    "tpot = TPOTClassifier(generations=4, population_size=40, verbosity=2, random_state=42,config_dict='TPOT sparse')\n",
    "tpot.fit(X_train_transformed, y_train)\n",
    "tpot.export('tpot_products_pipeline_countvectorizer.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of best TPOT Model with Sklearn Count Vectorizer\n",
      "Accuracy = 0.91, Precision = 0.5417671563253672, Recall = 0.7916065993913183, F1-score = 0.6432801822323462\n",
      "Confusion Matrix is:\n",
      "[[53555  4180]\n",
      " [ 1301  4942]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Average CV score on the training set was: 0.9571977297478277\n",
    "exported_pipeline = LinearSVC(C=0.5, dual=False, loss=\"squared_hinge\", penalty=\"l1\", tol=0.1)\n",
    "# Fix random state in exported estimator\n",
    "if hasattr(exported_pipeline, 'random_state'):\n",
    "    setattr(exported_pipeline, 'random_state', 42)\n",
    "\n",
    "exported_pipeline.fit(X_train_transformed, y_train)\n",
    "prediction = exported_pipeline.predict(X_test_transformed)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score as accuracy\n",
    "from sklearn.metrics import recall_score as recall\n",
    "from sklearn.metrics import precision_score as precision\n",
    "from sklearn.metrics import f1_score\n",
    " \n",
    "cmtp = confusion_matrix(y_test_relevant, prediction)\n",
    "acc  = accuracy(y_test_relevant, prediction)\n",
    "rec  = recall(y_test_relevant, prediction)\n",
    "prec = precision(y_test_relevant, prediction)\n",
    "f1   = f1_score(y_test_relevant, prediction)\n",
    "\n",
    "print('Result of best TPOT Model with Sklearn Count Vectorizer')\n",
    "print(f'Accuracy = {round(acc,2)}, Precision = {prec}, Recall = {rec}, F1-score = {f1}')\n",
    "print('Confusion Matrix is:')\n",
    "print(cmtp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.91, Precision = 0.5317035052467068, Recall = 0.7629344866250201, F1-score = 0.6266692980724953\n",
      "Confusion Matrix is:\n",
      "[[53540  4195]\n",
      " [ 1480  4763]]\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB(alpha=0.1)\n",
    "clf.fit(X_train_transformed, y_train)    \n",
    "prediction= clf.predict(X_test_transformed)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score as accuracy\n",
    "from sklearn.metrics import recall_score as recall\n",
    "from sklearn.metrics import precision_score as precision\n",
    "from sklearn.metrics import f1_score\n",
    " \n",
    "cmtp = confusion_matrix(y_test_relevant, prediction)\n",
    "acc  = accuracy(y_test_relevant, prediction)\n",
    "rec  = recall(y_test_relevant, prediction)\n",
    "prec = precision(y_test_relevant, prediction)\n",
    "f1   = f1_score(y_test_relevant, prediction)\n",
    "\n",
    "print('Result of Navie Bayes Model with Sklearn Count Vectorizer')\n",
    "print(f'Accuracy = {round(acc,2)}, Precision = {prec}, Recall = {rec}, F1-score = {f1}')\n",
    "print('Confusion Matrix is:')\n",
    "print(cmtp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sklearn - Tfidf Vectorizer\n",
    "Convert a collection of raw documents to a matrix of TF-IDF features.\n",
    "Equivalent to CountVectorizer followed by TfidfTransformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Train Test Data\n",
    "df_train = pd.read_csv('D:/Personal-GIT/data/kaggle_toxic/train.csv')\n",
    "df_test = pd.read_csv('D:/Personal-GIT/data/kaggle_toxic/test.csv')\n",
    "y_test  = pd.read_csv('D:/Personal-GIT/data/kaggle_toxic/test_labels.csv')\n",
    "\n",
    "## Test train features\n",
    "X_train = df_train.drop(columns=['id', 'toxic','severe_toxic', 'obscene','threat','insult','identity_hate'])\n",
    "X_test  = df_test.drop(columns=['id']) \n",
    "y_train = df_train[['toxic','severe_toxic', 'obscene','threat','insult','identity_hate']].apply(lambda x: 1 if sum(x) else 0, axis=1)\n",
    "y_test[['target']] = y_test[['toxic','severe_toxic', 'obscene','threat','insult','identity_hate']].apply(lambda x: 1 if sum(x) else 0, axis=1)\n",
    "y_test[['Missing']] = y_test[['toxic','severe_toxic', 'obscene','threat','insult','identity_hate']].apply(lambda x: min(x), axis=1)\n",
    "y_test_relevant = y_test[y_test['Missing']!=-1]['target']\n",
    "X_test_relevant = X_test[y_test['Missing']!=-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(the     1.399704\n",
       " to      1.523261\n",
       " and     1.683704\n",
       " of      1.735374\n",
       " you     1.745691\n",
       " is      1.786071\n",
       " it      1.843795\n",
       " that    1.875579\n",
       " in      1.942687\n",
       " for     2.058241\n",
       " this    2.074570\n",
       " not     2.123774\n",
       " on      2.172444\n",
       " be      2.187330\n",
       " have    2.307512\n",
       " as      2.352069\n",
       " are     2.355101\n",
       " if      2.427280\n",
       " with    2.437017\n",
       " but     2.512216\n",
       " dtype: float64,\n",
       " 0000000                     12.287103\n",
       " 00000000                    12.287103\n",
       " 0000000027                  12.287103\n",
       " 00000001                    12.287103\n",
       " 00000003                    12.287103\n",
       " 00000050                    12.287103\n",
       " 000001                      12.287103\n",
       " 000002                      12.287103\n",
       " 000002000004000008000016    12.287103\n",
       " 0000030422                  12.287103\n",
       " 0000035                     12.287103\n",
       " 000023405011                12.287103\n",
       " 00004                       12.287103\n",
       " 000045                      12.287103\n",
       " 00007632                    12.287103\n",
       " 000080                      12.287103\n",
       " 00008b                      12.287103\n",
       " 00009c                      12.287103\n",
       " 000111002                   12.287103\n",
       " 00012                       12.287103\n",
       " dtype: float64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tf-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vect = TfidfVectorizer().fit(X_train['comment_text'])\n",
    "\n",
    "#top and bottom features based on tf-idf.\n",
    "feature_names = vect.get_feature_names()\n",
    "idfs = vect.idf_\n",
    "names_idfs = list(zip(feature_names, idfs))\n",
    "\n",
    "import operator\n",
    "#smallest tf-idfs\n",
    "smallest = sorted(names_idfs, key=operator.itemgetter(1))[:20]\n",
    "smallest = pd.Series([features[1] for features in smallest], index=[features[0] for features in smallest])\n",
    "\n",
    "largest = sorted(names_idfs, key=operator.itemgetter(1), reverse=True)[:20]\n",
    "largest = sorted(largest, key=operator.itemgetter(0))\n",
    "largest = pd.Series([features[1] for features in largest], index=[features[0] for features in largest])\n",
    "\n",
    "(smallest, largest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Features Shape = (159571, 189775)\n",
      "Relevant Test Features Shape = (63978, 189775)\n",
      "Train set y mean = 0.10167887648758234\n",
      "Test set y mean = 0.09758041826877989\n"
     ]
    }
   ],
   "source": [
    "# Transform test and train data based on tf-idf\n",
    "X_train_transformed = vect.fit_transform(X_train['comment_text'])\n",
    "X_test_transformed = vect.transform(X_test_relevant['comment_text'])\n",
    "\n",
    "#Dimenstions of test and train sets.\n",
    "print(f'Train Features Shape = {X_train_transformed.shape}')\n",
    "print(f'Relevant Test Features Shape = {X_test_transformed.shape}')\n",
    "\n",
    "#Compare - Train Test Distributions.\n",
    "print(f'Train set y mean = {np.mean(y_train)}')\n",
    "print(f'Test set y mean = {np.mean(y_test_relevant)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tpot\\builtins\\__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.\n",
      "  warnings.warn(\"Warning: optional dependency `torch` is not available. - skipping import of NN models.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Optimization Progress'), FloatProgress(value=0.0, max=200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.9619855722036774\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.9620294400986452\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.9620294400986452\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.9620294400986452\n",
      "\n",
      "Best pipeline: LinearSVC(CombineDFs(input_matrix, input_matrix), C=0.5, dual=False, loss=squared_hinge, penalty=l1, tol=0.01)\n"
     ]
    }
   ],
   "source": [
    "## TRAIN MODEL\n",
    "#TPOT Sparse Classsifier \n",
    "from tpot import TPOTClassifier\n",
    "tpot = TPOTClassifier(generations=4, population_size=40, verbosity=2, random_state=42,config_dict='TPOT sparse')\n",
    "tpot.fit(X_train_transformed, y_train)\n",
    "tpot.export('tpot_tfidfvectorizer.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of best TPOT Model with Sklearn Count Vectorizer\n",
      "Accuracy = 0.92, Precision = 0.5775466845577547, Recall = 0.8273266057984943, F1-score = 0.6802317924404057\n",
      "Confusion Matrix is:\n",
      "[[53957  3778]\n",
      " [ 1078  5165]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.svm import LinearSVC\n",
    "from tpot.builtins import StackingEstimator\n",
    "from tpot.export_utils import set_param_recursive\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from copy import copy\n",
    "\n",
    "# Average CV score on the training set was: 0.9620294400986452\n",
    "exported_pipeline = make_pipeline(\n",
    "    make_union(\n",
    "        FunctionTransformer(copy),\n",
    "        FunctionTransformer(copy)\n",
    "    ),\n",
    "    LinearSVC(C=0.5, dual=False, loss=\"squared_hinge\", penalty=\"l1\", tol=0.01)\n",
    ")\n",
    "# Fix random state for all the steps in exported pipeline\n",
    "set_param_recursive(exported_pipeline.steps, 'random_state', 42)\n",
    "\n",
    "exported_pipeline.fit(X_train_transformed, y_train)\n",
    "prediction = exported_pipeline.predict(X_test_transformed)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score as accuracy\n",
    "from sklearn.metrics import recall_score as recall\n",
    "from sklearn.metrics import precision_score as precision\n",
    "from sklearn.metrics import f1_score\n",
    " \n",
    "cmtp = confusion_matrix(y_test_relevant, prediction)\n",
    "acc  = accuracy(y_test_relevant, prediction)\n",
    "rec  = recall(y_test_relevant, prediction)\n",
    "prec = precision(y_test_relevant, prediction)\n",
    "f1   = f1_score(y_test_relevant, prediction)\n",
    "\n",
    "\n",
    "print('Result of best TPOT Model with Sklearn Tf-IDF')\n",
    "print(f'Accuracy = {round(acc,2)}, Precision = {prec}, Recall = {rec}, F1-score = {f1}')\n",
    "print('Confusion Matrix is:')\n",
    "\n",
    "print(cmtp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bi-grams and Tri-grams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Train Test Data\n",
    "df_train = pd.read_csv('D:/Personal-GIT/data/kaggle_toxic/train.csv')\n",
    "df_test = pd.read_csv('D:/Personal-GIT/data/kaggle_toxic/test.csv')\n",
    "y_test  = pd.read_csv('D:/Personal-GIT/data/kaggle_toxic/test_labels.csv')\n",
    "\n",
    "## Test train features\n",
    "X_train = df_train.drop(columns=['id', 'toxic','severe_toxic', 'obscene','threat','insult','identity_hate'])\n",
    "X_test  = df_test.drop(columns=['id']) \n",
    "y_train = df_train[['toxic','severe_toxic', 'obscene','threat','insult','identity_hate']].apply(lambda x: 1 if sum(x) else 0, axis=1)\n",
    "y_test[['target']] = y_test[['toxic','severe_toxic', 'obscene','threat','insult','identity_hate']].apply(lambda x: 1 if sum(x) else 0, axis=1)\n",
    "y_test[['Missing']] = y_test[['toxic','severe_toxic', 'obscene','threat','insult','identity_hate']].apply(lambda x: min(x), axis=1)\n",
    "y_test_relevant = y_test[y_test['Missing']!=-1]['target']\n",
    "X_test_relevant = X_test[y_test['Missing']!=-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sklearn - \n",
    "# CountVectorizer with uni, bi and tri grams & \n",
    "#limit max features to 2000 top max_features ordered by term frequency across the corpus.\n",
    "\n",
    "import operator\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer(stop_words='english',ngram_range = (1,3),max_features=1000).fit(X_train['comment_text'])\n",
    "\n",
    "features = (vect.get_feature_names())\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(the     1.399704\n",
       " to      1.523261\n",
       " and     1.683704\n",
       " of      1.735374\n",
       " you     1.745691\n",
       " is      1.786071\n",
       " it      1.843795\n",
       " that    1.875579\n",
       " in      1.942687\n",
       " for     2.058241\n",
       " this    2.074570\n",
       " not     2.123774\n",
       " on      2.172444\n",
       " be      2.187330\n",
       " have    2.307512\n",
       " as      2.352069\n",
       " are     2.355101\n",
       " if      2.427280\n",
       " with    2.437017\n",
       " but     2.512216\n",
       " dtype: float64,\n",
       " 00 00 00           12.287103\n",
       " 00 00 14           12.287103\n",
       " 00 00 18           12.287103\n",
       " 00 00 19           12.287103\n",
       " 00 00 20           12.287103\n",
       " 00 00 30           12.287103\n",
       " 00 00 on           12.287103\n",
       " 00 00 sky          12.287103\n",
       " 00 00 the          12.287103\n",
       " 00 00 utc          12.287103\n",
       " 00 000             12.287103\n",
       " 00 000 times       12.287103\n",
       " 00 00pm            12.287103\n",
       " 00 00pm at         12.287103\n",
       " 00 00utc           12.287103\n",
       " 00 00utc please    12.287103\n",
       " 00 01 02           12.287103\n",
       " 00 01 10           12.287103\n",
       " 00 01 14           12.287103\n",
       " 00 01 2004         12.287103\n",
       " dtype: float64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tf-IDF with uni/bi and tri-grams\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vect = TfidfVectorizer(ngram_range = (1,3)).fit(X_train['comment_text'])\n",
    "\n",
    "#top and bottom features based on tf-idf.\n",
    "feature_names = vect.get_feature_names()\n",
    "idfs = vect.idf_\n",
    "names_idfs = list(zip(feature_names, idfs))\n",
    "\n",
    "import operator\n",
    "#smallest tf-idfs\n",
    "smallest = sorted(names_idfs, key=operator.itemgetter(1))[:20]\n",
    "smallest = pd.Series([features[1] for features in smallest], index=[features[0] for features in smallest])\n",
    "\n",
    "largest = sorted(names_idfs, key=operator.itemgetter(1), reverse=True)[:20]\n",
    "largest = sorted(largest, key=operator.itemgetter(0))\n",
    "largest = pd.Series([features[1] for features in largest], index=[features[0] for features in largest])\n",
    "\n",
    "(smallest, largest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Features Shape = (159571, 8144648)\n",
      "Relevant Test Features Shape = (63978, 8144648)\n",
      "Train set y mean = 0.10167887648758234\n",
      "Test set y mean = 0.09758041826877989\n"
     ]
    }
   ],
   "source": [
    "# Transform test and train data based on tf-idf\n",
    "X_train_transformed = vect.fit_transform(X_train['comment_text'])\n",
    "X_test_transformed = vect.transform(X_test_relevant['comment_text'])\n",
    "\n",
    "#Dimenstions of test and train sets.\n",
    "print(f'Train Features Shape = {X_train_transformed.shape}')\n",
    "print(f'Relevant Test Features Shape = {X_test_transformed.shape}')\n",
    "\n",
    "#Compare - Train Test Distributions.\n",
    "print(f'Train set y mean = {np.mean(y_train)}')\n",
    "print(f'Test set y mean = {np.mean(y_test_relevant)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tpot\\builtins\\__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.\n",
      "  warnings.warn(\"Warning: optional dependency `torch` is not available. - skipping import of NN models.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dec31e5ad2e42c3a6383089ba096ec2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Optimization Progress'), FloatProgress(value=0.0, max=120.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## TRAIN MODEL\n",
    "#TPOT Sparse Classsifier \n",
    "from tpot import TPOTClassifier\n",
    "tpot = TPOTClassifier(generations=2, population_size=40, verbosity=2, random_state=42,config_dict='TPOT sparse')\n",
    "tpot.fit(X_train_transformed, y_train)\n",
    "tpot.export('tpot_tfidfvectorizer_bi_grams.py')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
